{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0b9632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv(dotenv_path=\"/home/bipin/Documents/genai/g25-aug/genai_25_sept/.env\")\n",
    "llm=ChatOpenAI(model=\"gpt-4.1-nano\")\n",
    "\n",
    "# initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efc3f178",
   "metadata": {},
   "outputs": [],
   "source": [
    "response= llm.invoke(\"what is langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ceebcca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langchain is an open-source framework designed to simplify the development of applications that utilize large language models (LLMs), such as GPT-4 or GPT-3. It provides tools and abstractions to help developers build, deploy, and manage complex AI-powered systems, including chatbots, question-answering systems, conversational agents, and more.\\n\\nKey features of Langchain include:\\n\\n- **Prompt management:** Tools to design, optimize, and manage prompts efficiently.\\n- **Chain construction:** Modular components to connect multiple language model calls, APIs, and data sources into cohesive workflows.\\n- **Memory and state management:** Maintaining context across interactions for more natural conversations.\\n- **Integrations:** Easy connection to various data sources like databases, APIs, and documents.\\n- **Agents:** Frameworks to enable LLMs to decide how to act based on given tools or APIs, facilitating more autonomous AI applications.\\n\\nOverall, Langchain aims to streamline building sophisticated LLM-based applications by providing a robust, flexible toolkit for handling prompts, data, and interactions.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 207, 'prompt_tokens': 11, 'total_tokens': 218, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CImuCkVYXzKDTtshQ2D53qQeIFEeP', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--280b4ac2-2e81-41cf-947e-ce3c9aaf6a4e-0' usage_metadata={'input_tokens': 11, 'output_tokens': 207, 'total_tokens': 218, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54e65496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langchain is an open-source framework designed to simplify the development of applications that utilize large language models (LLMs), such as GPT-4 or GPT-3. It provides tools and abstractions to help developers build, deploy, and manage complex AI-powered systems, including chatbots, question-answering systems, conversational agents, and more.\n",
      "\n",
      "Key features of Langchain include:\n",
      "\n",
      "- **Prompt management:** Tools to design, optimize, and manage prompts efficiently.\n",
      "- **Chain construction:** Modular components to connect multiple language model calls, APIs, and data sources into cohesive workflows.\n",
      "- **Memory and state management:** Maintaining context across interactions for more natural conversations.\n",
      "- **Integrations:** Easy connection to various data sources like databases, APIs, and documents.\n",
      "- **Agents:** Frameworks to enable LLMs to decide how to act based on given tools or APIs, facilitating more autonomous AI applications.\n",
      "\n",
      "Overall, Langchain aims to streamline building sophisticated LLM-based applications by providing a robust, flexible toolkit for handling prompts, data, and interactions.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e22cb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token_usage': {'completion_tokens': 207, 'prompt_tokens': 11, 'total_tokens': 218, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CImuCkVYXzKDTtshQ2D53qQeIFEeP', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "print(response.response_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a386f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c200b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a96902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4141e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5c3b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62651d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg = SystemMessage(\"You are a banking assistent answer only query related to banking only nothing else.\")\n",
    "human_msg = HumanMessage(\"what is photosynthesis?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3cad62e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "message =[system_msg,human_msg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cec907a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a banking assistent answer only query related to banking only nothing else.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is photosynthesis?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cad084b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "banking_response = llm.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddd9b972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I can only assist with banking-related queries. How may I help you with your banking needs today?\n"
     ]
    }
   ],
   "source": [
    "print(banking_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277dde9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a147a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5614f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"yore expert in summarizing text\"),\n",
    "    human_msg,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5c00999b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='yore expert in summarizing text', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is photosynthesis?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c33d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c514ccfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photosynthesis is the biological process by which green plants, algae, and some bacteria convert light energy, usually from the Sun, into chemical energy stored in glucose molecules. During this process, these organisms take in carbon dioxide (CO₂) from the air and water (H₂O) from the soil. Using the energy from sunlight captured by chlorophyll in their cells, they produce glucose (C₆H₁₂O₆) and oxygen (O₂) as byproducts. Photosynthesis is essential for producing the oxygen we breathe and forming the base of the food chain in most ecosystems.\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f89fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "156d816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a poetry expert\"),\n",
    "    HumanMessage(\"Write a haiku about spring\"),\n",
    "    AIMessage(\"Cherry blossoms bloom...\")\n",
    "]\n",
    "response = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c5bfc621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Petals dance in breeze,  \\nSpring awakens vibrant life—  \\nNature’s gentle smile.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde956bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29317aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a88df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4b05cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4809ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_language = \"English\"\n",
    "output_language = \"German\"\n",
    "user_text = \"I love programming.\"\n",
    "\n",
    "combined = (\n",
    "    f\"SYSTEM: You are a helpful assistant that translates {input_language} to {output_language}.\\n\\n\"\n",
    "    \"INSTRUCTION: Translate the user's text below into the target language. Output only the translation.\\n\\n\"\n",
    "    \"USER TEXT:\\n\"\n",
    "    f\"{user_text}\\n\"\n",
    ")\n",
    "\n",
    "# invoke with string\n",
    "response = llm.invoke(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "448fbf7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ich liebe Programmieren.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a34d30f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476bda2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb84c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c5a315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6062b9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54315190",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "system_msg = SystemMessage(\"You are a helpful assistant.\")\n",
    "human_msg = HumanMessage(\"Hello, how are you?\")\n",
    "\n",
    "# Use with chat models\n",
    "messages = [system_msg, human_msg]\n",
    "response = llm.invoke(messages)  # Returns AIMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b04f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chaining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a35f2cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ich liebe Programmieren.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 26, 'total_tokens': 31, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CImNcF02qjpd0Wi0M39aEGIaCUTx7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b8950d1f-d2dd-4cbb-b02d-a0176cf543d8-0', usage_metadata={'input_tokens': 26, 'output_tokens': 5, 'total_tokens': 31, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c299cb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Ich liebe Programmieren.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 39, 'total_tokens': 44, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CImOfFAutF77eqTLCubxVdBG8A4a0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--5e034dc5-a4fc-48f5-bf31-52a58cd586e6-0' usage_metadata={'input_tokens': 39, 'output_tokens': 5, 'total_tokens': 44, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that translates {input_language} to {output_language}.\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"Sure — I will translate the text now.\")   # fixed assistant message\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "resp = chain.invoke({\n",
    "    \"input_language\": \"English\",\n",
    "    \"output_language\": \"German\",\n",
    "    \"input\": \"I love programming.\"\n",
    "})\n",
    "print(resp)   # chain.invoke returns LLM result (or formatted output depending on your chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b60b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-25-sept",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
