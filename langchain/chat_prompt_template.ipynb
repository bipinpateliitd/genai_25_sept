{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad76d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv(dotenv_path=\"/home/bipin/Documents/genai/g25-aug/genai_25_sept/.env\")\n",
    "llm=ChatOpenAI(model=\"gpt-4.1-nano\", max_completion_tokens=200)\n",
    "\n",
    "\n",
    "# !pip install langchafrom langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# Define a chat prompt template\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful AI assistant.\",\n",
    "        ),\n",
    "        (\"human\", \"Tell me a joke about{topic}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "chain2 = prompt | llm\n",
    "\n",
    "output2 = chain2.invoke({\"topic\": \"programmers\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f826d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Sure! Here's a programmer joke for you:\\n\\nWhy do programmers prefer dark mode?\\n\\nBecause light attracts bugs!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 25, 'total_tokens': 46, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CImXdBvTb9kSGNbSCodSPCsyqUwzG', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--ba25f8f4-a3eb-4ab0-a8c7-9267e62020dd-0', usage_metadata={'input_tokens': 25, 'output_tokens': 21, 'total_tokens': 46, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde4b14a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83712616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# Define a multi-turn chat prompt template\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a helpful AI assistant.\"),\n",
    "    HumanMessage(content=\"Hi, my name is Suresh.\"),\n",
    "    AIMessage(content=\"Hello, Suresh! How can I help you today?\"),\n",
    "    HumanMessage(content=\"I need help with python.\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18fb2a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"user\", \"Tell me a joke about {animal}.\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a265691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# Define a chat prompt template with partial variables\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a {role}.\"),\n",
    "    HumanMessage(content=\"{user_input}\"),\n",
    "])\n",
    "partial_template = template.partial(role=\"math tutor\")\n",
    "\n",
    "prompt_value = partial_template.invoke({\"user_input\": \"Explain the Pythagorean theorem.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1b13cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# Define a role-playing chat prompt template\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a pirate. Speak like a pirate.\"),\n",
    "    HumanMessage(content=\"Tell me about your adventures.\"),\n",
    "])\n",
    "\n",
    "prompt_value = template.invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5296a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a99833",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd2ac4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eb3f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67efcfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# Define a chat prompt template with a MessagesPlaceholder\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    HumanMessage(content=\"{question}\"),\n",
    "])\n",
    "\n",
    "# Simulate a conversation history\n",
    "history = [\n",
    "    HumanMessage(content=\"What's 5 + 2?\"),\n",
    "    AIMessage(content=\"5 + 2 is 7.\"),\n",
    "]\n",
    "\n",
    "# Invoke the template with the history and a new question\n",
    "prompt_value = template.invoke({\n",
    "    \"history\": history,\n",
    "    \"question\": \"Now multiply that by 4.\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c71206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# Define a chat prompt template with an optional MessagesPlaceholder\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\", optional=True),\n",
    "    HumanMessage(content=\"{question}\"),\n",
    "])\n",
    "\n",
    "# Invoke the template without providing a history\n",
    "prompt_value = template.invoke({\n",
    "    \"question\": \"What is the capital of France?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15623466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# Define a chat prompt template with a MessagesPlaceholder limited to 2 messages\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\", n_messages=2),\n",
    "    HumanMessage(content=\"{question}\"),\n",
    "])\n",
    "\n",
    "# Simulate a conversation history\n",
    "history = [\n",
    "    HumanMessage(content=\"What's 5 + 2?\"),\n",
    "    AIMessage(content=\"5 + 2 is 7.\"),\n",
    "    HumanMessage(content=\"Now multiply that by 4.\"),\n",
    "    AIMessage(content=\"7 * 4 is 28.\"),\n",
    "]\n",
    "\n",
    "# Invoke the template with the history and a new question\n",
    "prompt_value = template.invoke({\n",
    "    \"history\": history,\n",
    "    \"question\": \"What's the square root of that?\"\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-25-sept",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
