{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Prompt Engineering Types Tutorial\n",
    "\n",
    "## A Beginner's Guide to Different Prompt Engineering Techniques using LangChain\n",
    "\n",
    "This tutorial provides clear, simple examples of different prompt engineering types and techniques. Perfect for beginners who want to understand the fundamentals before diving into complex applications.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Prompt Engineering Fundamentals](#1-prompt-engineering-fundamentals)\n",
    "2. [Core Prompt Engineering Types](#2-core-prompt-engineering-types)\n",
    "3. [Simple Practical Examples](#3-simple-practical-examples)\n",
    "4. [Prompt Optimization Techniques](#4-prompt-optimization-techniques)\n",
    "5. [Common Patterns and Templates](#5-common-patterns-and-templates)\n",
    "6. [Interactive Examples with LangChain](#6-interactive-examples-with-langchain)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from typing import List, Dict\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(dotenv_path=\"/home/bipin/Documents/genai/g25-aug/genai_25_sept/.env\")\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", max_completion_tokens=500, temperature=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Prompt Engineering Fundamentals\n",
    "\n",
    "### What is Prompt Engineering?\n",
    "\n",
    "Prompt engineering is the art and science of crafting effective instructions for AI language models. Think of it as learning how to communicate clearly with a very smart but literal assistant.\n",
    "\n",
    "### Why Does It Matter?\n",
    "- **Better Results**: Well-crafted prompts produce more accurate and useful responses\n",
    "- **Consistency**: Good prompts give consistent results across multiple uses\n",
    "- **Efficiency**: Save time by getting the right answer on the first try\n",
    "- **Control**: Guide the AI's behavior and output format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Principles\n",
    "\n",
    "#### 1. Be Clear and Specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bad prompt: Vague and unclear\n",
    "bad_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"Tell me about dogs\")\n",
    "])\n",
    "\n",
    "# Good prompt: Clear and specific\n",
    "good_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"List 5 popular dog breeds suitable for apartment living, including their size and key characteristics\")\n",
    "])\n",
    "\n",
    "# Test both prompts\n",
    "print(\"=== BAD PROMPT (Vague) ===\")\n",
    "bad_chain = bad_prompt | llm\n",
    "bad_response = bad_chain.invoke({})\n",
    "print(bad_response.content[:200] + \"...\\n\")\n",
    "\n",
    "print(\"=== GOOD PROMPT (Specific) ===\")\n",
    "good_chain = good_prompt | llm\n",
    "good_response = good_chain.invoke({})\n",
    "print(good_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Provide Context When Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without context\n",
    "no_context_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"Should I invest in this stock?\")\n",
    "])\n",
    "\n",
    "# With context\n",
    "with_context_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"\"\"I'm a 25-year-old software engineer with a stable income and $10,000 to invest. \n",
    "    I have a moderate risk tolerance and a 10-year investment timeline. \n",
    "    Should I invest in Apple stock (AAPL) which is currently trading at $150 with a P/E ratio of 25?\"\"\")\n",
    "])\n",
    "\n",
    "print(\"=== WITHOUT CONTEXT ===\")\n",
    "no_context_chain = no_context_prompt | llm\n",
    "no_context_response = no_context_chain.invoke({})\n",
    "print(no_context_response.content[:200] + \"...\\n\")\n",
    "\n",
    "print(\"=== WITH CONTEXT ===\")\n",
    "with_context_chain = with_context_prompt | llm\n",
    "with_context_response = with_context_chain.invoke({})\n",
    "print(with_context_response.content[:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Core Prompt Engineering Types\n",
    "\n",
    "Let's explore the main types of prompt engineering techniques with simple, clear examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Zero-Shot Prompting\n",
    "\n",
    "**What it is**: Asking the AI to perform a task without providing any examples.\n",
    "\n",
    "**When to use**: For straightforward tasks where the AI already understands what you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot example: Sentiment analysis\n",
    "zero_shot_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a sentiment analyzer. Classify the sentiment of the given text as POSITIVE, NEGATIVE, or NEUTRAL.\"),\n",
    "    (\"human\", \"Text: {text}\\n\\nSentiment:\")\n",
    "])\n",
    "\n",
    "# Test with different texts\n",
    "test_texts = [\n",
    "    \"I absolutely love this new restaurant! The food is amazing.\",\n",
    "    \"The weather today is okay, nothing special.\",\n",
    "    \"I hate waiting in long lines. This is frustrating.\"\n",
    "]\n",
    "\n",
    "zero_shot_chain = zero_shot_template | llm\n",
    "\n",
    "print(\"=== ZERO-SHOT SENTIMENT ANALYSIS ===\")\n",
    "for i, text in enumerate(test_texts, 1):\n",
    "    response = zero_shot_chain.invoke({\"text\": text})\n",
    "    print(f\"{i}. Text: '{text}'\")\n",
    "    print(f\"   Sentiment: {response.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 One-Shot Prompting\n",
    "\n",
    "**What it is**: Providing exactly one example to show the AI what you want.\n",
    "\n",
    "**When to use**: When you need to demonstrate a specific format or style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-shot example: Product description generation\n",
    "one_shot_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You generate engaging product descriptions for e-commerce. Follow the example format.\"),\n",
    "    (\"human\", \"Product: Wireless Headphones\\nFeatures: Noise-cancelling, 30-hour battery, Bluetooth 5.0\"),\n",
    "    (\"ai\", \"üéß **Premium Wireless Headphones** üéß\\n\\n‚ú® Experience crystal-clear audio with advanced noise-cancelling technology\\nüîã All-day listening with impressive 30-hour battery life\\nüì± Seamless connectivity with latest Bluetooth 5.0\\n\\nPerfect for music lovers and professionals alike!\"),\n",
    "    (\"human\", \"Product: {product}\\nFeatures: {features}\")\n",
    "])\n",
    "\n",
    "# Test the one-shot approach\n",
    "one_shot_chain = one_shot_template | llm\n",
    "response = one_shot_chain.invoke({\n",
    "    \"product\": \"Smartwatch\",\n",
    "    \"features\": \"Heart rate monitoring, GPS tracking, Water-resistant, 7-day battery\"\n",
    "})\n",
    "\n",
    "print(\"=== ONE-SHOT PRODUCT DESCRIPTION ===\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Few-Shot Prompting\n",
    "\n",
    "**What it is**: Providing multiple examples to help the AI learn a pattern.\n",
    "\n",
    "**When to use**: For complex tasks where you need consistent formatting or when the task isn't obvious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot example: Email categorization\n",
    "examples = [\n",
    "    {\n",
    "        \"email\": \"Your order #12345 has been shipped and will arrive tomorrow.\",\n",
    "        \"category\": \"ORDER_UPDATE\"\n",
    "    },\n",
    "    {\n",
    "        \"email\": \"Don't miss our 50% off sale this weekend only!\",\n",
    "        \"category\": \"PROMOTION\"\n",
    "    },\n",
    "    {\n",
    "        \"email\": \"We're sorry to hear about your recent experience. Please reply with details.\",\n",
    "        \"category\": \"CUSTOMER_SERVICE\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create few-shot template\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"Email: {email}\"),\n",
    "    (\"ai\", \"Category: {category}\")\n",
    "])\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You categorize emails into: ORDER_UPDATE, PROMOTION, CUSTOMER_SERVICE, or OTHER\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"Email: {email}\")\n",
    "])\n",
    "\n",
    "# Test few-shot learning\n",
    "few_shot_chain = final_prompt | llm\n",
    "test_email = \"Thank you for your feedback! We've updated our privacy policy.\"\n",
    "\n",
    "response = few_shot_chain.invoke({\"email\": test_email})\n",
    "\n",
    "print(\"=== FEW-SHOT EMAIL CATEGORIZATION ===\")\n",
    "print(f\"Test Email: '{test_email}'\")\n",
    "print(f\"Result: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Chain-of-Thought Prompting\n",
    "\n",
    "**What it is**: Asking the AI to think step-by-step and show its reasoning.\n",
    "\n",
    "**When to use**: For complex problems that require logical reasoning or multi-step solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain-of-thought example: Math word problems\n",
    "cot_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You solve math problems step by step. Always show your reasoning clearly.\"),\n",
    "    (\"human\", \"\"\"Let's work through this step by step.\n",
    "\n",
    "Problem: {problem}\n",
    "\n",
    "Please think through this step by step:\n",
    "1. What information do we have?\n",
    "2. What do we need to find?\n",
    "3. What steps do we need to take?\n",
    "4. Show the calculations\n",
    "5. State the final answer\n",
    "\"\"\")\n",
    "])\n",
    "\n",
    "# Test with a word problem\n",
    "math_problem = \"A store sells books for $15 each. If they offer a 20% discount for buying 5 or more books, how much would it cost to buy 8 books?\"\n",
    "\n",
    "cot_chain = cot_template | llm\n",
    "response = cot_chain.invoke({\"problem\": math_problem})\n",
    "\n",
    "print(\"=== CHAIN-OF-THOUGHT PROBLEM SOLVING ===\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Role-Based Prompting\n",
    "\n",
    "**What it is**: Assigning the AI a specific role or persona to guide its responses.\n",
    "\n",
    "**When to use**: When you need expertise from a specific perspective or want a particular communication style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Role-based prompting examples\n",
    "roles = {\n",
    "    \"teacher\": \"You are an elementary school teacher explaining concepts to 8-year-old students. Use simple words and fun examples.\",\n",
    "    \"scientist\": \"You are a research scientist. Provide accurate, technical explanations with scientific terminology.\",\n",
    "    \"comedian\": \"You are a friendly comedian. Make your explanations funny and entertaining while staying informative.\"\n",
    "}\n",
    "\n",
    "def create_role_prompt(role_description):\n",
    "    return ChatPromptTemplate.from_messages([\n",
    "        (\"system\", role_description),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "\n",
    "question = \"Why do we have seasons?\"\n",
    "\n",
    "print(\"=== ROLE-BASED PROMPTING COMPARISON ===\")\n",
    "print(f\"Question: {question}\\n\")\n",
    "\n",
    "for role_name, role_desc in roles.items():\n",
    "    role_template = create_role_prompt(role_desc)\n",
    "    role_chain = role_template | llm\n",
    "    response = role_chain.invoke({\"question\": question})\n",
    "    \n",
    "    print(f\"=== {role_name.upper()} PERSPECTIVE ===\")\n",
    "    print(response.content[:300] + \"...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Simple Practical Examples\n",
    "\n",
    "Let's apply these techniques to common real-world tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News article classification\n",
    "classification_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Classify news articles into categories: TECHNOLOGY, SPORTS, POLITICS, BUSINESS, HEALTH, ENTERTAINMENT.\n",
    "    \n",
    "    Output format: CATEGORY - Brief reason\"\"\"),\n",
    "    (\"human\", \"Article headline: {headline}\\n\\nClassify this article:\")\n",
    "])\n",
    "\n",
    "headlines = [\n",
    "    \"New iPhone Release Features Revolutionary Camera Technology\",\n",
    "    \"Local Basketball Team Wins Championship After 20-Year Drought\",\n",
    "    \"Stock Market Reaches New High Amid Economic Recovery\",\n",
    "    \"Scientists Discover New Treatment for Common Cold\"\n",
    "]\n",
    "\n",
    "classification_chain = classification_template | llm\n",
    "\n",
    "print(\"=== NEWS ARTICLE CLASSIFICATION ===\")\n",
    "for i, headline in enumerate(headlines, 1):\n",
    "    response = classification_chain.invoke({\"headline\": headline})\n",
    "    print(f\"{i}. '{headline}'\")\n",
    "    print(f\"   ‚Üí {response.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract structured information from text\n",
    "extraction_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Extract key information from the text and format as JSON with these fields:\n",
    "    {\n",
    "        \"name\": \"person's name\",\n",
    "        \"age\": \"age if mentioned\",\n",
    "        \"location\": \"city/state\",\n",
    "        \"occupation\": \"job title\",\n",
    "        \"interests\": [\"list\", \"of\", \"hobbies\"]\n",
    "    }\n",
    "    \n",
    "    Use \"unknown\" for missing information.\"\"\"),\n",
    "    (\"human\", \"Text: {text}\")\n",
    "])\n",
    "\n",
    "sample_text = \"\"\"Meet Sarah Johnson, a 28-year-old software engineer living in Austin, Texas. \n",
    "She loves hiking, photography, and playing guitar in her spare time. Sarah has been \n",
    "coding for over 5 years and recently started her own tech startup.\"\"\"\n",
    "\n",
    "extraction_chain = extraction_template | llm\n",
    "response = extraction_chain.invoke({\"text\": sample_text})\n",
    "\n",
    "print(\"=== INFORMATION EXTRACTION ===\")\n",
    "print(f\"Original Text: {sample_text}\\n\")\n",
    "print(f\"Extracted Information:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Content Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate social media posts\n",
    "content_generation_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You create engaging social media posts. Include:\n",
    "    - Catchy opening\n",
    "    - Key message\n",
    "    - Call to action\n",
    "    - Relevant hashtags\n",
    "    \n",
    "    Keep it under 280 characters for Twitter-style posts.\"\"\"),\n",
    "    (\"human\", \"\"\"Topic: {topic}\n",
    "    Target audience: {audience}\n",
    "    Tone: {tone}\n",
    "    \n",
    "    Create a social media post:\"\"\")\n",
    "])\n",
    "\n",
    "content_requests = [\n",
    "    {\n",
    "        \"topic\": \"New coffee shop opening\",\n",
    "        \"audience\": \"Local coffee lovers\",\n",
    "        \"tone\": \"Excited and welcoming\"\n",
    "    },\n",
    "    {\n",
    "        \"topic\": \"Tips for working from home\",\n",
    "        \"audience\": \"Remote workers\",\n",
    "        \"tone\": \"Helpful and professional\"\n",
    "    }\n",
    "]\n",
    "\n",
    "content_chain = content_generation_template | llm\n",
    "\n",
    "print(\"=== CONTENT GENERATION ===\")\n",
    "for i, request in enumerate(content_requests, 1):\n",
    "    response = content_chain.invoke(request)\n",
    "    print(f\"Post {i} - {request['topic']}:\")\n",
    "    print(response.content)\n",
    "    print(f\"Characters: {len(response.content)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Question Answering with Different Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different QA approaches\n",
    "context = \"\"\"Python is a high-level programming language created by Guido van Rossum \n",
    "and first released in 1991. It's known for its simple, readable syntax that \n",
    "emphasizes code readability. Python supports multiple programming paradigms \n",
    "including procedural, object-oriented, and functional programming. It's widely \n",
    "used in web development, data science, artificial intelligence, and automation.\"\"\"\n",
    "\n",
    "question = \"What is Python used for?\"\n",
    "\n",
    "# Approach 1: Direct QA\n",
    "direct_qa = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"Question: {question}\")\n",
    "])\n",
    "\n",
    "# Approach 2: Context-based QA\n",
    "context_qa = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"Context: {context}\\n\\nQuestion: {question}\\n\\nAnswer based on the context:\")\n",
    "])\n",
    "\n",
    "# Approach 3: Step-by-step QA\n",
    "step_qa = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"\"\"Context: {context}\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Please:\n",
    "    1. Identify relevant information from the context\n",
    "    2. Provide a clear answer\n",
    "    3. Explain your reasoning\"\"\")\n",
    "])\n",
    "\n",
    "approaches = [\n",
    "    (\"Direct QA (no context)\", direct_qa, {\"question\": question}),\n",
    "    (\"Context-based QA\", context_qa, {\"context\": context, \"question\": question}),\n",
    "    (\"Step-by-step QA\", step_qa, {\"context\": context, \"question\": question})\n",
    "]\n",
    "\n",
    "print(\"=== QUESTION ANSWERING COMPARISON ===\")\n",
    "print(f\"Question: {question}\\n\")\n",
    "\n",
    "for approach_name, template, inputs in approaches:\n",
    "    chain = template | llm\n",
    "    response = chain.invoke(inputs)\n",
    "    print(f\"=== {approach_name} ===\")\n",
    "    print(response.content[:250] + \"...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Prompt Optimization Techniques\n",
    "\n",
    "Learn how to make your prompts more effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Instruction Clarity: Clear vs Vague"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare vague vs clear instructions\n",
    "vague_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"Write about {topic}\")\n",
    "])\n",
    "\n",
    "clear_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"\"\"Write a 150-word informative paragraph about {topic} that:\n",
    "    1. Defines what it is\n",
    "    2. Explains why it's important\n",
    "    3. Gives 2 practical examples\n",
    "    4. Uses simple language suitable for beginners\n",
    "    \n",
    "    Format: One cohesive paragraph, no bullet points.\"\"\")\n",
    "])\n",
    "\n",
    "topic = \"machine learning\"\n",
    "\n",
    "print(\"=== INSTRUCTION CLARITY COMPARISON ===\")\n",
    "print(f\"Topic: {topic}\\n\")\n",
    "\n",
    "# Vague version\n",
    "vague_chain = vague_prompt | llm\n",
    "vague_response = vague_chain.invoke({\"topic\": topic})\n",
    "print(\"=== VAGUE INSTRUCTIONS ===\")\n",
    "print(vague_response.content[:300] + \"...\\n\")\n",
    "\n",
    "# Clear version\n",
    "clear_chain = clear_prompt | llm\n",
    "clear_response = clear_chain.invoke({\"topic\": topic})\n",
    "print(\"=== CLEAR INSTRUCTIONS ===\")\n",
    "print(clear_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Output Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structured output formatting\n",
    "formatting_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You analyze products and provide structured reviews.\"),\n",
    "    (\"human\", \"\"\"Product: {product}\n",
    "    Price: {price}\n",
    "    Features: {features}\n",
    "    \n",
    "    Provide a review in this exact format:\n",
    "    \n",
    "    ## Product Review: [Product Name]\n",
    "    \n",
    "    **Rating:** [1-5 stars] ‚≠ê\n",
    "    **Price:** [price evaluation - expensive/reasonable/budget]\n",
    "    \n",
    "    **Pros:**\n",
    "    ‚Ä¢ [pro 1]\n",
    "    ‚Ä¢ [pro 2]\n",
    "    \n",
    "    **Cons:**\n",
    "    ‚Ä¢ [con 1]\n",
    "    ‚Ä¢ [con 2]\n",
    "    \n",
    "    **Best For:** [target user]\n",
    "    \n",
    "    **Bottom Line:** [one sentence summary]\"\"\")\n",
    "])\n",
    "\n",
    "product_info = {\n",
    "    \"product\": \"Wireless Gaming Mouse\",\n",
    "    \"price\": \"$79.99\",\n",
    "    \"features\": \"RGB lighting, 16000 DPI, 70-hour battery, ergonomic design\"\n",
    "}\n",
    "\n",
    "formatting_chain = formatting_template | llm\n",
    "response = formatting_chain.invoke(product_info)\n",
    "\n",
    "print(\"=== STRUCTURED OUTPUT FORMATTING ===\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Temperature Control: Creativity vs Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different temperature settings\n",
    "creative_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"Write a creative opening sentence for a story about {scenario}\")\n",
    "])\n",
    "\n",
    "scenario = \"a robot discovering emotions\"\n",
    "\n",
    "# Different temperature models\n",
    "conservative_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)  # Low creativity, high consistency\n",
    "balanced_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)     # Balanced\n",
    "creative_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=1.0)     # High creativity, low consistency\n",
    "\n",
    "models = [\n",
    "    (\"Conservative (temp=0.1)\", conservative_llm),\n",
    "    (\"Balanced (temp=0.7)\", balanced_llm),\n",
    "    (\"Creative (temp=1.0)\", creative_llm)\n",
    "]\n",
    "\n",
    "print(\"=== TEMPERATURE COMPARISON ===\")\n",
    "print(f\"Scenario: {scenario}\\n\")\n",
    "\n",
    "for model_name, model in models:\n",
    "    chain = creative_prompt | model\n",
    "    response = chain.invoke({\"scenario\": scenario})\n",
    "    print(f\"=== {model_name} ===\")\n",
    "    print(response.content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Common Patterns and Templates\n",
    "\n",
    "Reusable patterns for common tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 The STAR Pattern (Situation, Task, Action, Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAR pattern for structured responses\n",
    "star_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You provide structured responses using the STAR method:\n",
    "    - Situation: Set the context\n",
    "    - Task: Describe what needed to be done\n",
    "    - Action: Explain the steps taken\n",
    "    - Result: Share the outcome\n",
    "    \n",
    "    Format each section clearly with headers.\"\"\"),\n",
    "    (\"human\", \"Describe how to handle this scenario using the STAR method: {scenario}\")\n",
    "])\n",
    "\n",
    "scenario = \"A team project is behind schedule with conflicting opinions on priorities\"\n",
    "\n",
    "star_chain = star_template | llm\n",
    "response = star_chain.invoke({\"scenario\": scenario})\n",
    "\n",
    "print(\"=== STAR PATTERN EXAMPLE ===\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Multi-Step Problem Solving Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-step problem solving\n",
    "problem_solving_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You solve problems systematically. Always follow this structure:\n",
    "    \n",
    "    üîç **ANALYZE THE PROBLEM**\n",
    "    - What is the main issue?\n",
    "    - What are the constraints?\n",
    "    - What resources are available?\n",
    "    \n",
    "    üéØ **IDENTIFY SOLUTIONS**\n",
    "    - List 2-3 possible approaches\n",
    "    - Consider pros and cons of each\n",
    "    \n",
    "    ‚ö° **RECOMMENDED ACTION**\n",
    "    - Choose the best approach\n",
    "    - Provide step-by-step implementation\n",
    "    \n",
    "    üìä **MEASURE SUCCESS**\n",
    "    - How will you know it worked?\n",
    "    - What metrics to track?\n",
    "    \"\"\"),\n",
    "    (\"human\", \"Problem: {problem}\")\n",
    "])\n",
    "\n",
    "problem = \"Our website loads slowly on mobile devices, causing users to leave\"\n",
    "\n",
    "problem_solving_chain = problem_solving_template | llm\n",
    "response = problem_solving_chain.invoke({\"problem\": problem})\n",
    "\n",
    "print(\"=== MULTI-STEP PROBLEM SOLVING ===\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Conditional Logic Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template with conditional responses\n",
    "conditional_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You provide personalized fitness advice based on experience level:\n",
    "    \n",
    "    - BEGINNER (0-6 months): Focus on form, basic exercises, 2-3 days/week\n",
    "    - INTERMEDIATE (6 months - 2 years): Progressive overload, 3-4 days/week\n",
    "    - ADVANCED (2+ years): Complex movements, specialized programs, 4-6 days/week\n",
    "    \n",
    "    Tailor your advice to their level. Include specific exercises and rep ranges.\"\"\"),\n",
    "    (\"human\", \"\"\"User Profile:\n",
    "    - Experience level: {level}\n",
    "    - Goal: {goal}\n",
    "    - Available time: {time_available}\n",
    "    - Equipment: {equipment}\n",
    "    \n",
    "    Provide a personalized fitness plan.\"\"\")\n",
    "])\n",
    "\n",
    "user_profiles = [\n",
    "    {\n",
    "        \"level\": \"BEGINNER\",\n",
    "        \"goal\": \"lose weight\",\n",
    "        \"time_available\": \"30 minutes, 3 days/week\",\n",
    "        \"equipment\": \"none (bodyweight only)\"\n",
    "    },\n",
    "    {\n",
    "        \"level\": \"INTERMEDIATE\",\n",
    "        \"goal\": \"build muscle\",\n",
    "        \"time_available\": \"45 minutes, 4 days/week\",\n",
    "        \"equipment\": \"full gym access\"\n",
    "    }\n",
    "]\n",
    "\n",
    "conditional_chain = conditional_template | llm\n",
    "\n",
    "print(\"=== CONDITIONAL LOGIC TEMPLATES ===\")\n",
    "for i, profile in enumerate(user_profiles, 1):\n",
    "    response = conditional_chain.invoke(profile)\n",
    "    print(f\"=== User {i}: {profile['level']} ===\")\n",
    "    print(response.content[:400] + \"...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Error Handling and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template with input validation\n",
    "validation_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You help with recipe calculations. Before calculating:\n",
    "    \n",
    "    1. CHECK if the input makes sense:\n",
    "       - Is the number of servings reasonable (1-50)?\n",
    "       - Are ingredients listed?\n",
    "       - Is the original serving size mentioned?\n",
    "    \n",
    "    2. If input is invalid, politely ask for clarification\n",
    "    3. If valid, provide scaled recipe with clear measurements\n",
    "    \n",
    "    Always double-check your math!\"\"\"),\n",
    "    (\"human\", \"\"\"Original recipe serves: {original_servings}\n",
    "    Ingredients: {ingredients}\n",
    "    Need to serve: {target_servings}\n",
    "    \n",
    "    Please scale this recipe.\"\"\")\n",
    "])\n",
    "\n",
    "# Test with valid and invalid inputs\n",
    "test_cases = [\n",
    "    {\n",
    "        \"original_servings\": \"4\",\n",
    "        \"ingredients\": \"2 cups flour, 1 cup sugar, 3 eggs, 1/2 cup butter\",\n",
    "        \"target_servings\": \"8\"\n",
    "    },\n",
    "    {\n",
    "        \"original_servings\": \"unclear\",\n",
    "        \"ingredients\": \"some flour, sugar\",\n",
    "        \"target_servings\": \"100\"\n",
    "    }\n",
    "]\n",
    "\n",
    "validation_chain = validation_template | llm\n",
    "\n",
    "print(\"=== INPUT VALIDATION EXAMPLE ===\")\n",
    "for i, case in enumerate(test_cases, 1):\n",
    "    response = validation_chain.invoke(case)\n",
    "    print(f\"=== Test Case {i} ===\")\n",
    "    print(f\"Input: Serves {case['original_servings']} ‚Üí {case['target_servings']}\")\n",
    "    print(f\"Response: {response.content[:300]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Interactive Examples with LangChain\n",
    "\n",
    "Advanced LangChain features for prompt engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Prompt Comparison Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool to compare different prompt approaches\n",
    "class PromptTester:\n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "    \n",
    "    def compare_prompts(self, prompts_dict, input_data):\n",
    "        results = {}\n",
    "        \n",
    "        for name, template in prompts_dict.items():\n",
    "            chain = template | self.llm\n",
    "            response = chain.invoke(input_data)\n",
    "            results[name] = {\n",
    "                'response': response.content,\n",
    "                'length': len(response.content),\n",
    "                'template': str(template)\n",
    "            }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def print_comparison(self, results):\n",
    "        print(\"=== PROMPT COMPARISON RESULTS ===\")\n",
    "        for name, result in results.items():\n",
    "            print(f\"\\n=== {name} ===\")\n",
    "            print(f\"Length: {result['length']} characters\")\n",
    "            print(f\"Response: {result['response'][:200]}...\")\n",
    "\n",
    "# Create different prompt versions\n",
    "prompt_versions = {\n",
    "    \"Basic\": ChatPromptTemplate.from_messages([\n",
    "        (\"human\", \"Explain {concept}\")\n",
    "    ]),\n",
    "    \n",
    "    \"Detailed\": ChatPromptTemplate.from_messages([\n",
    "        (\"human\", \"Explain {concept} in simple terms with an example and why it's useful\")\n",
    "    ]),\n",
    "    \n",
    "    \"Structured\": ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Provide explanations in this format: Definition, Example, Benefits, Use Cases\"),\n",
    "        (\"human\", \"Explain: {concept}\")\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Test the prompts\n",
    "tester = PromptTester(llm)\n",
    "results = tester.compare_prompts(prompt_versions, {\"concept\": \"blockchain technology\"})\n",
    "tester.print_comparison(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Dynamic Prompt Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic prompt builder based on user needs\n",
    "class DynamicPromptBuilder:\n",
    "    def __init__(self):\n",
    "        self.base_system = \"You are a helpful assistant.\"\n",
    "        self.components = {\n",
    "            'role': {\n",
    "                'teacher': \"You are an experienced teacher who explains concepts clearly.\",\n",
    "                'expert': \"You are a subject matter expert providing detailed technical information.\",\n",
    "                'friend': \"You are a knowledgeable friend giving casual, friendly advice.\"\n",
    "            },\n",
    "            'format': {\n",
    "                'bullet': \"Format your response as bullet points.\",\n",
    "                'numbered': \"Format your response as numbered steps.\",\n",
    "                'paragraph': \"Format your response as flowing paragraphs.\"\n",
    "            },\n",
    "            'length': {\n",
    "                'brief': \"Keep your response under 100 words.\",\n",
    "                'moderate': \"Aim for 150-300 words.\",\n",
    "                'detailed': \"Provide a comprehensive response.\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def build_prompt(self, role=None, format_type=None, length=None, include_examples=False):\n",
    "        system_parts = []\n",
    "        \n",
    "        if role:\n",
    "            system_parts.append(self.components['role'].get(role, self.base_system))\n",
    "        \n",
    "        if format_type:\n",
    "            system_parts.append(self.components['format'].get(format_type, \"\"))\n",
    "        \n",
    "        if length:\n",
    "            system_parts.append(self.components['length'].get(length, \"\"))\n",
    "        \n",
    "        if include_examples:\n",
    "            system_parts.append(\"Include practical examples in your response.\")\n",
    "        \n",
    "        system_message = \" \".join(filter(None, system_parts))\n",
    "        \n",
    "        return ChatPromptTemplate.from_messages([\n",
    "            (\"system\", system_message),\n",
    "            (\"human\", \"{question}\")\n",
    "        ])\n",
    "\n",
    "# Test dynamic prompt building\n",
    "builder = DynamicPromptBuilder()\n",
    "\n",
    "configurations = [\n",
    "    {\"role\": \"teacher\", \"format_type\": \"numbered\", \"length\": \"brief\", \"name\": \"Teacher Style\"},\n",
    "    {\"role\": \"expert\", \"format_type\": \"paragraph\", \"length\": \"detailed\", \"include_examples\": True, \"name\": \"Expert Style\"},\n",
    "    {\"role\": \"friend\", \"format_type\": \"bullet\", \"length\": \"moderate\", \"name\": \"Friendly Style\"}\n",
    "]\n",
    "\n",
    "question = \"How does photosynthesis work?\"\n",
    "\n",
    "print(\"=== DYNAMIC PROMPT BUILDER ===\")\n",
    "print(f\"Question: {question}\\n\")\n",
    "\n",
    "for config in configurations:\n",
    "    name = config.pop('name')  # Remove name from config\n",
    "    prompt = builder.build_prompt(**config)\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"question\": question})\n",
    "    \n",
    "    print(f\"=== {name} ===\")\n",
    "    print(response.content[:250] + \"...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Prompt Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple metrics for prompt effectiveness\n",
    "import time\n",
    "import re\n",
    "\n",
    "class PromptMetrics:\n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "    \n",
    "    def analyze_prompt(self, template, input_data, runs=3):\n",
    "        chain = template | self.llm\n",
    "        responses = []\n",
    "        times = []\n",
    "        \n",
    "        for _ in range(runs):\n",
    "            start_time = time.time()\n",
    "            response = chain.invoke(input_data)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            responses.append(response.content)\n",
    "            times.append(end_time - start_time)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        avg_length = sum(len(r) for r in responses) / len(responses)\n",
    "        avg_time = sum(times) / len(times)\n",
    "        consistency = self._calculate_consistency(responses)\n",
    "        readability = self._calculate_readability(responses[0])\n",
    "        \n",
    "        return {\n",
    "            'average_length': avg_length,\n",
    "            'average_time': avg_time,\n",
    "            'consistency': consistency,\n",
    "            'readability_score': readability,\n",
    "            'sample_response': responses[0]\n",
    "        }\n",
    "    \n",
    "    def _calculate_consistency(self, responses):\n",
    "        # Simple consistency check based on length variation\n",
    "        lengths = [len(r) for r in responses]\n",
    "        if not lengths:\n",
    "            return 0\n",
    "        avg = sum(lengths) / len(lengths)\n",
    "        variance = sum((l - avg) ** 2 for l in lengths) / len(lengths)\n",
    "        return max(0, 100 - (variance ** 0.5))\n",
    "    \n",
    "    def _calculate_readability(self, text):\n",
    "        # Simple readability score (higher = more readable)\n",
    "        sentences = len(re.split(r'[.!?]+', text))\n",
    "        words = len(text.split())\n",
    "        if sentences == 0:\n",
    "            return 0\n",
    "        avg_words_per_sentence = words / sentences\n",
    "        # Prefer 10-20 words per sentence\n",
    "        optimal_range = (10, 20)\n",
    "        if optimal_range[0] <= avg_words_per_sentence <= optimal_range[1]:\n",
    "            return 100\n",
    "        else:\n",
    "            distance = min(abs(avg_words_per_sentence - optimal_range[0]),\n",
    "                         abs(avg_words_per_sentence - optimal_range[1]))\n",
    "            return max(0, 100 - distance * 5)\n",
    "\n",
    "# Test prompt metrics\n",
    "metrics = PromptMetrics(llm)\n",
    "\n",
    "test_prompts = {\n",
    "    \"Simple\": ChatPromptTemplate.from_messages([\n",
    "        (\"human\", \"What is {topic}?\")\n",
    "    ]),\n",
    "    \"Detailed\": ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Provide clear, concise explanations suitable for beginners.\"),\n",
    "        (\"human\", \"Explain {topic} in simple terms with one example.\")\n",
    "    ])\n",
    "}\n",
    "\n",
    "topic = \"artificial intelligence\"\n",
    "\n",
    "print(\"=== PROMPT PERFORMANCE METRICS ===\")\n",
    "for name, template in test_prompts.items():\n",
    "    results = metrics.analyze_prompt(template, {\"topic\": topic})\n",
    "    \n",
    "    print(f\"\\n=== {name} Prompt ===\")\n",
    "    print(f\"Average Length: {results['average_length']:.1f} characters\")\n",
    "    print(f\"Average Time: {results['average_time']:.2f} seconds\")\n",
    "    print(f\"Consistency Score: {results['consistency']:.1f}/100\")\n",
    "    print(f\"Readability Score: {results['readability_score']:.1f}/100\")\n",
    "    print(f\"Sample: {results['sample_response'][:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Key Takeaways\n",
    "\n",
    "### üéØ **Main Prompt Engineering Types**:\n",
    "\n",
    "1. **Zero-Shot**: Direct task execution without examples\n",
    "   - Best for: Simple, well-defined tasks\n",
    "   - Example: \"Classify this sentiment as positive, negative, or neutral\"\n",
    "\n",
    "2. **One-Shot**: Single example to guide behavior\n",
    "   - Best for: Demonstrating specific format or style\n",
    "   - Example: Show one product description, then ask for another\n",
    "\n",
    "3. **Few-Shot**: Multiple examples for pattern learning\n",
    "   - Best for: Complex formatting or classification tasks\n",
    "   - Example: Show 3 email categorization examples, then classify new emails\n",
    "\n",
    "4. **Chain-of-Thought**: Step-by-step reasoning\n",
    "   - Best for: Complex problem-solving, math, logical reasoning\n",
    "   - Example: \"Let's solve this step by step: 1) What do we know? 2) What formula applies?\"\n",
    "\n",
    "5. **Role-Based**: Assign specific persona or expertise\n",
    "   - Best for: Specialized knowledge or communication style\n",
    "   - Example: \"You are a pediatric nurse explaining vaccines to worried parents\"\n",
    "\n",
    "### üöÄ **Optimization Tips**:\n",
    "\n",
    "- **Be Specific**: Clear instructions beat vague requests every time\n",
    "- **Provide Context**: Help the AI understand the situation\n",
    "- **Format Output**: Specify exactly how you want the response structured\n",
    "- **Control Temperature**: Low for consistency, high for creativity\n",
    "- **Test and Iterate**: Try different approaches and measure results\n",
    "\n",
    "### üõ†Ô∏è **Practical Applications**:\n",
    "\n",
    "- **Content Creation**: Blogs, social media, marketing copy\n",
    "- **Data Analysis**: Classification, extraction, summarization\n",
    "- **Customer Service**: FAQ responses, support tickets\n",
    "- **Education**: Explanations, tutorials, assessments\n",
    "- **Decision Support**: Analysis, recommendations, comparisons\n",
    "\n",
    "### üìà **Next Steps**:\n",
    "\n",
    "1. **Practice**: Try each prompt type with your own use cases\n",
    "2. **Measure**: Track what works best for your specific needs\n",
    "3. **Build Templates**: Create reusable prompts for common tasks\n",
    "4. **Combine Techniques**: Mix different approaches for complex scenarios\n",
    "5. **Stay Updated**: Prompt engineering evolves with new models and techniques\n",
    "\n",
    "---\n",
    "\n",
    "**Remember**: Good prompt engineering is part art, part science. Start simple, be specific, and always test your results! üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}